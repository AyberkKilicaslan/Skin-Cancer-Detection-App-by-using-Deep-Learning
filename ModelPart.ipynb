{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edd9eb48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.summary API due to missing TensorBoard installation.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from sklearn.metrics import confusion_matrix,plot_confusion_matrix\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D , BatchNormalization\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage.morphology import extrema\n",
    "from skimage.morphology import watershed as skwater\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from sklearn.metrics import confusion_matrix,plot_confusion_matrix\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D , BatchNormalization\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage.morphology import extrema\n",
    "from skimage.morphology import watershed as skwater\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7768ad4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = []\n",
    "img_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c442ede7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4120/4120 [00:20<00:00, 204.47it/s]\n"
     ]
    }
   ],
   "source": [
    "path = 'hairremoved'\n",
    "all_images = os.listdir(path)\n",
    "i = 0\n",
    "for ix in tqdm(os.listdir(path)):\n",
    "    out = path +\"/\" + all_images[i]\n",
    "    img = cv2.imread(out)\n",
    "    img = cv2.resize(img, (224,224))\n",
    "    img_list.append(img)\n",
    "    label_list.append(1)\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9cdae2d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6154/6154 [00:19<00:00, 314.95it/s]\n"
     ]
    }
   ],
   "source": [
    "path = 'nonmel_hairremoved'\n",
    "all_images = os.listdir(path)\n",
    "i = 0\n",
    "for ix in tqdm(os.listdir(path)):\n",
    "    if i < 4121:\n",
    "        out = path +\"/\" + all_images[i]\n",
    "        img = cv2.imread(out)\n",
    "        if img is None:\n",
    "            print('Wrong path:', path)\n",
    "        else:\n",
    "            img = cv2.resize(img, (224,224))\n",
    "            img_list.append(img)\n",
    "            label_list.append(0)\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bddcba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.array(img_list)\n",
    "lbl = np.array(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "894ea0f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8241, 240, 240, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af875094",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test,y_train, y_test = train_test_split(img,lbl, test_size=0.1,random_state=32, shuffle= True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "743b93d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ayberk\\anaconda3\\envs\\tfp\\lib\\site-packages\\keras_applications\\mobilenet.py:207: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  warnings.warn('`input_shape` is undefined or non-square, '\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications.mobilenet import MobileNet, decode_predictions, preprocess_input\n",
    "vgg_model = MobileNet(weights='imagenet', include_top=False, input_shape=(224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "88548c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in vgg_model.layers:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "64cd7432",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelVGG16 = Sequential()\n",
    "modelVGG16.add(vgg_model)\n",
    "modelVGG16.add(Flatten())\n",
    "modelVGG16.add(Dense(1024, activation='relu'))\n",
    "modelVGG16.add(Dropout(0.2))\n",
    "modelVGG16.add(Dense(512, activation='relu'))\n",
    "modelVGG16.add(Dropout(0.2))\n",
    "modelVGG16.add(Dense(256, activation='relu'))\n",
    "modelVGG16.add(Dropout(0.2))\n",
    "modelVGG16.add(Dense(128, activation='relu'))\n",
    "modelVGG16.add(Dropout(0.2))\n",
    "modelVGG16.add(Dense(64, activation='relu'))\n",
    "modelVGG16.add(Dropout(0.2))\n",
    "modelVGG16.add(Dense(32, activation='relu'))\n",
    "modelVGG16.add(Dropout(0.2))\n",
    "modelVGG16.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile model \n",
    "modelVGG16.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy',\n",
    "                                                                          tf.keras.metrics.Precision(),\n",
    "                                                                          tf.keras.metrics.Recall()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a9737553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7416 samples\n",
      "Epoch 1/5\n",
      "7416/7416 [==============================] - 116s 16ms/sample - loss: 0.9297 - accuracy: 0.6458 - precision_1: 0.6558 - recall_1: 0.6197\n",
      "Epoch 2/5\n",
      "7416/7416 [==============================] - 111s 15ms/sample - loss: 0.6180 - accuracy: 0.7001 - precision_1: 0.7042 - recall_1: 0.6943\n",
      "Epoch 3/5\n",
      "7416/7416 [==============================] - 112s 15ms/sample - loss: 0.5949 - accuracy: 0.7074 - precision_1: 0.7054 - recall_1: 0.7164\n",
      "Epoch 4/5\n",
      "7416/7416 [==============================] - 112s 15ms/sample - loss: 0.5634 - accuracy: 0.7408 - precision_1: 0.7615 - recall_1: 0.7043\n",
      "Epoch 5/5\n",
      "7416/7416 [==============================] - 112s 15ms/sample - loss: 0.5489 - accuracy: 0.7364 - precision_1: 0.7523 - recall_1: 0.7080\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1983c96ba58>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelVGG16.fit(X_train, y_train,batch_size=10, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "559cb090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "825/825 [==============================] - 3s 4ms/sample - loss: 0.4968 - accuracy: 0.7503 - precision_1: 0.8577 - recall_1: 0.5768\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.496832092964288, 0.75030303, 0.8576779, 0.5768262]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelVGG16.evaluate(X_test, y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f825aa22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
